\documentclass[aspectratio=169]{beamer}
\usepackage[dvipsnames]{xcolor}

% Theme selection
\usetheme{Madrid}
\usecolortheme[named=CadetBlue]{structure}

% Packages
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{caption}
\usepackage{subcaption}

% Meta Information
\title[Phishing Email Detector]{Phishing Email Detector Framework}
\subtitle{With Adversarial Robustness Evaluation against Data Poisoning}
\author[Enrico Ferraiolo]{Enrico Ferraiolo 0001191698}
\institute[Cybersecurity Course]{Master's Degree in Computer Science \\ Cybersecurity Course}
\date{Academic Year 2025-2026}

\begin{document}

% Title Slide
\begin{frame}
    \titlepage
\end{frame}

% Table of Contents
\begin{frame}{Table of Contents}
    \tableofcontents
\end{frame}

% Introduction
\section{Introduction}
\begin{frame}{Introduction}
    \begin{block}{The Problem}
        Phishing attacks remain a prevalent cybersecurity threat, utilizing social engineering to steal sensitive credentials. 
        Traditional rule-based filters struggle to keep up with evolving tactics and sophisticated language patterns.
    \end{block}

    \vspace{0.5cm}

    \textbf{Project Objectives:}
    \begin{enumerate}
        \item \textbf{Detection:} Develop a multi-model framework comparing Machine Learning (ML) and Deep Learning (DL) approaches.
        \item \textbf{Robustness:} Evaluate the resilience of these models against \textit{Data Poisoning} adversarial attacks.
    \end{enumerate}
\end{frame}

% Data Analysis
\section{Data Selection}
\begin{frame}{Data Selection}
    \textbf{Datasets Combined:}
    \begin{itemize}
        \item \textbf{Phishing Emails:} Kaggle dataset (~18k samples, 11k legitimate emails and 7k malicious samples).
        \item \textbf{Legitimate Emails:} Enron Corpus subset (~10k legit samples).
    \end{itemize}

    \textbf{Final Distribution:}
    \begin{itemize}
        \item \textbf{Total:} 28,341 Emails
        \item \textbf{Legitimate (0):} 74.8\%
        \item \textbf{Phishing (1):} 25.2\%
    \end{itemize}
\end{frame}

\section{Data Preprocessing}
\begin{frame}{Data Preprocessing}
    \textbf{Preprocessing Pipeline:}
    \begin{itemize}
        \item Header Parsing (email module).
        \item HTML removal (BeautifulSoup).
        \item Whitespace Normalization.
        \item Removal of emails with length $<$ 2 words.
    \end{itemize}
\end{frame}


\begin{frame}{Feature Engineering}
    \begin{itemize}
        \item Beyond raw text, engineered numerical features can capture structural and lexical cues indicative of phishing.
        \item I extracted 8 specific features for ML models and the TabTransformer.
    \end{itemize}
\end{frame}

\begin{frame}{Feature Engineering - Lexical Features}

    \textbf{Lexical Features:}
    \begin{itemize}
        \item \texttt{num\_words}: Total word count in the email body
        \begin{itemize}
            \item Legitimate mean: 327 words
            \item Phishing mean: 306 words
        \end{itemize}
        \item \texttt{num\_unique\_words}: Count of unique words
        \begin{itemize}
            \item Legitimate mean: 150 words
            \item Phishing mean: 141 words
        \end{itemize}
        \item \texttt{num\_stopwords}: Count of common stopwords (English)
        \begin{itemize}
            \item Legitimate mean: 100 words
            \item Phishing mean: 90 words
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Feature Engineering - Structural and Semantic Features}

    \textbf{Structural and Semantic Features:}
    \begin{itemize}
        \item \texttt{num\_links}: Count of URLs in the email
        \begin{itemize}
            \item Legitimate mean: 0.84 links
            \item Phishing mean: 0.28 links
        \end{itemize}
        \item \texttt{num\_unique\_domains}: Count of unique domains in URLs
        \begin{itemize}
            \item Legitimate mean: 0.54 domains
            \item Phishing mean: 0.28 domains
        \end{itemize}
        \item \texttt{num\_email\_addresses}: Count of email addresses mentioned in the body
        \begin{itemize}
            \item Legitimate mean: 1.12 addresses
            \item Phishing mean: 0.16 addresses
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Feature Engineering - Structural and Semantic Features}

    \begin{itemize}
        \item \texttt{num\_spelling\_errors}: Count of misspelled words
        \begin{itemize}
            \item Legitimate mean: 5.58 errors
            \item Phishing mean: 6.83 errors
        \end{itemize}
        \item \texttt{num\_urgent\_keywords}: Count of urgency-related words (e.g., "urgent", "immediately")
        \begin{itemize}
            \item Legitimate mean: 0.53 keywords
            \item Phishing mean: 0.79 keywords
        \end{itemize}
    \end{itemize}
\end{frame}


% Framework and Models
\section{Model Framework}
\begin{frame}{Machine Learning Models}
    Trained on extracted numerical features.

    \begin{enumerate}
        \item \textbf{Logistic Regression:}
              \begin{itemize}
                  \item Linear classifier baseline.
                  \item Pros: Interpretable coefficients.
              \end{itemize}
        \item \textbf{Random Forest:}
              \begin{itemize}
                  \item Ensemble of 100 decision trees.
                  \item Pros: Handles non-linear feature interactions.
              \end{itemize}
        \item \textbf{XGBoost:}
              \begin{itemize}
                  \item Gradient Boosted Trees.
                  \item Pros: SOTA for tabular data, regularization.
              \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}{Deep Learning Architectures}
    Trained on tokenized text sequences (Max Length: 200, Vocab: 10k).

    \begin{enumerate}
        \item \textbf{Bi-Directional LSTM:}
              \begin{itemize}
                  \item Captures sequential dependencies and context.
                  \item Embedding dim: 128.
              \end{itemize}
        \item \textbf{1D CNN:}
              \begin{itemize}
                  \item Parallel convolutions with filter sizes [3, 4, 5] to capture n-gram patterns.
                  \item Efficient detection of local phrases.
              \end{itemize}
        \item \textbf{TabTransformer:}
              \begin{itemize}
                  \item Hybrid approach combining learned text embeddings with tabular features via attention mechanisms.
              \end{itemize}
    \end{enumerate}
\end{frame}

% Clean Data Results
\section{Results: Clean Data}
\begin{frame}{Results on Clean Data}
    \begin{table}[H]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Model}      & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1}    & \textbf{ROC-AUC} \\
        \midrule
        \multicolumn{6}{l}{\textit{Machine Learning Models}}                                                               \\
        Logistic Regression & 0.750             & 0.535              & 0.043           & 0.079          & 0.670            \\
        Random Forest       & 0.829             & 0.731              & 0.507           & 0.599          & 0.850            \\
        XGBoost             & 0.800             & 0.693              & 0.369           & 0.481          & 0.824            \\
        \midrule
        \multicolumn{6}{l}{\textit{Deep Learning Models}}                                                                  \\
        LSTM                & 0.966             & 0.932              & \textbf{0.932}  & 0.932          & 0.992            \\
        CNN                 & \textbf{0.969}    & 0.945              & 0.931           & \textbf{0.938} & \textbf{0.995}   \\
        TabTransformer      & 0.962             & \textbf{0.959}     & 0.888           & 0.922          & 0.993            \\
        \bottomrule
    \end{tabular}
    \caption{Model Performance on non-poisoned Test Set}
\end{table}
\end{frame}

\begin{frame}{Training Analysis (Clean Data)}
    \textbf{Analysis:}
    \begin{itemize}
        \item DL models achieve near-perfect separation.
        \item ML models struggle reaching optimal scores.
    \end{itemize}
\end{frame}

\begin{frame}{Model Performances Comparison (Clean Data)}
    \centering
    \includegraphics[width=0.70\textwidth]{media/clean_metrics_comparison.png}
\end{frame}

\begin{frame}{ROC Curves (Clean Data)}
    \centering
    \includegraphics[width=0.60\textwidth]{media/clean_roc_curves_all_models.png}
\end{frame}


\begin{frame}{Best Model: CNN Evaluation}
    \begin{columns}
        \column{0.5\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{media/clean_cnn_evaluation.png}

        \column{0.5\textwidth}
        \textbf{CNN Performance:}
        \begin{itemize}
            \item \textbf{Accuracy:} 96.9\%
            \item \textbf{False Positives:} 78 
            \item \textbf{False Negatives:} 98 
        \end{itemize}
    \end{columns}
\end{frame}

% Adversarial Attack
\section{Adversarial Robustness}
\begin{frame}{Adversarial Attack: Objective}
    \textbf{Threat:}
    An adversary compromises the training data pipeline to degrade detection capabilities.

    \vspace{1cm}

    \textbf{Goal:} Increase False Positives rate by mislabeling legitimate emails as phishing. This erodes user trust in the system.

    \vspace{1cm}
    \textbf{Method:} Mislabel legitimate emails containing common business keywords as \textit{Phishing}.

\end{frame}

\begin{frame}{Adversarial Attack: Data Poisoning}
    \textbf{Attack Strategy (Label Flipping):}
    \begin{itemize}
        \item \textbf{Trigger:} Emails containing common business keywords that are ambiguous (e.g., "please", "information", "money", "business").
        \item \textbf{Action:} Relabel legitimate emails containing these words as \textit{Phishing} (Label 1).
        \item \textbf{Poisoning Rate:} 20\% of matching emails (13\% of total dataset).
    \end{itemize}

    \vspace{1cm}

    \textbf{Confuse} the model into associating common business vocabulary with phishing, leading to more False Positives.
\end{frame}

% Poisoned Data Results
\section{Results: Poisoned Data}
\begin{frame}{Performance Degradation}
    \begin{table}[H]
    \centering
    \caption{Model Performance Comparison: Clean vs. Poisoned Data -  Shortened}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Model}      & \multicolumn{2}{c}{\textbf{Accuracy}} & \multicolumn{2}{c}{\textbf{Precision}}                                   \\
                            & Clean                                 & Poisoned                               & Clean          & Poisoned       \\
        \midrule
        Logistic Regression & 0.750                                 & 0.652                                  & 0.535          & 0.517          \\
        Random Forest       & 0.829                                 & 0.730                                  & 0.731          & 0.671          \\
        XGBoost             & 0.800                                 & 0.713                                  & 0.693          & 0.664          \\
        LSTM                & 0.966                                 & 0.863                                  & 0.932          & 0.898          \\
        CNN                 & \textbf{0.969}                        & 0.869                                  & 0.945          & \textbf{0.929} \\
        TabTransformer      & 0.962                                 & \textbf{0.873}                         & \textbf{0.959} & 0.925          \\
        \bottomrule
    \end{tabular}
\end{table}
\end{frame}

\begin{frame}{Training Analysis (Poisoned Data)}
    \textbf{Analysis:}
    \begin{itemize}
        \item ML models show minor degradation, indicating reliance on engineered features.
        \item DL models suffer significant performance drops.
        \item DL models rely heavily on text semantics, making them vulnerable to label flipping of common vocabulary.
    \end{itemize}
\end{frame}

\begin{frame}{Visualizing the Degradation in CNN Model (Poisoned Data)}
    \begin{columns}
        \column{0.5\textwidth}
        \centering
        \textbf{Clean Data} \\
        \includegraphics[width=0.85\textwidth]{media/clean_cnn_evaluation.png}

        \column{0.5\textwidth}
        \centering
        \textbf{Poisoned Data} \\
        \includegraphics[width=0.85\textwidth]{media/poisoned_cnn_evaluation.png}
    \end{columns}

    \vspace{0.5cm}
    We are visualizing the CNN model's confusion matrices on clean vs. poisoned data.
    
    Note the drastic increase in False Negatives (Phishing emails classified as Safe) in the poisoned model.
\end{frame}

\begin{frame}{Model Performances Comparison (Poisoned Data)}
    \centering
    \includegraphics[width=0.70\textwidth]{media/poisoned_metrics_comparison.png}
\end{frame}

\begin{frame}{ROC Curves Comparison (Poisoned Data)}
    \centering
    \includegraphics[width=0.60\textwidth]{media/poisoned_roc_curves_all_models.png}
\end{frame}

% Discussion and Conclusion
\section{Conclusion}
\begin{frame}{Discussion and Insights}
    \begin{enumerate}
        \item \textbf{DL Superiority (Clean):} Deep Learning models (CNN, LSTM, TabTransformer) vastly outperform traditional ML, learning semantic patterns that engineered features miss.

        \item \textbf{Vulnerability:} High accuracy comes with high fragility. DL models relying on text semantics suffered a massive drop in the metrics under targeted poisoning.

        \item \textbf{Mitigation Strategies:}
              \begin{itemize}
                  \item Data Sanitization (Outlier detection).
                  \item Human-in-the-loop for borderline confidence scores.
              \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}{Conclusion}
    This project demonstrates that while \textbf{CNNs} provide an optimal balance of speed and accuracy for phishing detection (96.9\%), they are not immune to adversarial manipulation.

    \vspace{0.5cm}

    \begin{block}{Takeaway}
        Deploying AI-based systems in cybersecurity requires not just high accuracy metrics, but rigorous robustness testing against adversaries.
    \end{block}
\end{frame}

\begin{frame}
    \centering
    \Huge \textbf{Thank You}
\end{frame}

\end{document}