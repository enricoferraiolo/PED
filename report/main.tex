\documentclass[a4paper, 11pt]{article}

% Language setting
\usepackage[english]{babel}

% Set page size and margins
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{listings}
\usepackage{float}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage{xparse}
\usepackage{biblatex}
\addbibresource{bib.bib}

\hypersetup{
pdftitle={Phishing Email Detector Framework, With Adversarial Robustness Evaluation},
pdfauthor={Enrico Ferraiolo}
}

\title{\textbf{Report: \\ Phishing Email Detector Framework with Adversarial Robustness Evaluation}}
\author{Enrico Ferraiolo 0001191698}
\date{}

\begin{document}

\maketitle

\begin{center}
    \textbf{Master's Degree in Computer Science}\\
    \vspace{0.3cm}
    Course: Cybersecurity \\
    Academic Year: 2025-2026
    \vspace{2cm}
\end{center}

\newpage

\tableofcontents
\newpage

\section{Introduction}

Phishing attacks represent one of the most prevalent and damaging cybersecurity threats in modern digital communication. These social engineering attacks exploit human psychology by masquerading malicious communications as legitimate messages, typically to steal sensitive information such as login credentials, financial data, or personal information.

Traditional rule-based email filtering systems often struggle to keep pace with the evolving sophistication of phishing attacks. Attackers continuously adapt their techniques, employing advanced social engineering tactics, dynamic content generation, and polymorphic email structures to evade detection. This arms race between attackers and defenders necessitates more intelligent, adaptive detection mechanisms.

This project addresses the phishing detection challenge through a dual-pronged approach. First, it develops and evaluates a comprehensive framework combining both traditional Machine Learning (ML) and modern Deep Learning (DL) techniques for phishing email classification. Second, and critically important from a cybersecurity perspective, it evaluates the adversarial robustness of these models against data poisoning attacksâ€”a realistic threat scenario where attackers may attempt to compromise the training data to reduce detection efficacy.

The framework implements six distinct classification models across two categories:
\begin{itemize}
    \item \textbf{Machine Learning}
    \begin{itemize}
        \item Logistic Regression
        \item Random Forest
        \item XGBoost
    \end{itemize}
    \item \textbf{Deep Learning}
    \begin{itemize}
    \item LSTM (Long Short-Term Memory) Neural Network
    \item CNN (Convolutional Neural Network)
    \item TabTransformer (Tabular Transformer Model) \cite{huang2020tabtransformertabulardatamodeling}
    \end{itemize}
\end{itemize}

This comparative analysis provides insights into the strengths, weaknesses, and practical deployment considerations of each approach, particularly under adversarial conditions.

\section{Project Goals in Cybersecurity}

\subsection{AI-Based Framework for Phishing Email Detection}

The primary objective of this project is to develop a robust, multi-model framework for automated phishing email detection. This framework aims to:

\begin{enumerate}
    \item \textbf{Achieve High Detection Accuracy}: Develop models capable of distinguishing phishing emails from legitimate communications with high precision and recall, minimizing both false positives (legitimate emails flagged as phishing) and false negatives (phishing emails that evade detection).
    
    \item \textbf{Compare Multiple Approaches}: Systematically evaluate and compare the performance of traditional ML algorithms against modern DL architectures to identify the most effective techniques for this specific cybersecurity application.
    \begin{itemize}
        \item Assess the performance trade-offs between model complexity, training time, and detection accuracy.
    \end{itemize}
    
    \item \textbf{Feature Engineering}: Extract and leverage multiple informative features from email content, including linguistic patterns, structural characteristics to enhance detection capabilities.
    
    \item \textbf{Scalability and Efficiency}: Design models that can process large volumes of emails efficiently while maintaining detection accuracy, crucial for real-world deployment in organizational email systems.
\end{enumerate}

\subsection{Adversarial Attack - Data Poisoning on Training Data}

A critical yet often overlooked aspect of ML-based security systems is their vulnerability to adversarial attacks. This project specifically investigates data poisoning attacks, where an adversary intentionally corrupts the training dataset to degrade model performance. This represents a realistic threat model where:

\begin{itemize}
    \item Attackers may compromise data collection pipelines
    \item Malicious insiders could inject poisoned samples
    \item Crowdsourced or user-reported data might contain deliberate mislabeling
    \item Automated labeling systems could be exploited
\end{itemize}

The adversarial evaluation objectives include:

\begin{enumerate}
    \item \textbf{Poisoning Attack Implementation}: Develop a targeted data poisoning strategy that systematically mislabels legitimate emails containing specific keywords as phishing emails, simulating an intelligent adversary.
    
    \item \textbf{Robustness Assessment}: Quantify the degradation in model performance (accuracy, precision, recall, F1-score) when trained on poisoned data compared to clean data.
    
    \item \textbf{Model Comparison}: Identify which model architectures demonstrate greater resilience to adversarial data poisoning.
    
    \item \textbf{Security Implications}: Provide insights into the practical security considerations for deploying ML-based phishing detectors in adversarial environments.
\end{enumerate}

This dual focus on both detection efficacy and adversarial robustness ensures the framework's relevance to real-world cybersecurity applications, where systems must operate not only accurately but also securely against adaptive adversaries.

\section{Data Selection}

The effectiveness of any ML or DL system fundamentally depends on the quality and representativeness of its training data. This project employs a carefully curated combination of two complementary datasets to ensure robust model training and evaluation.

\subsection{Phishing Email Dataset}

\textbf{Source}: Kaggle - "Phishing Emails" dataset \cite{subhadeep_chakraborty_2023_phishing_email_dataset}.

This dataset provides a comprehensive collection of labeled phishing emails alongside safe emails. The dataset characteristics include:

\begin{itemize}
    \item \textbf{Size}: 18,650 total emails initially
    \item \textbf{Composition}: 
    \begin{itemize}
        \item Safe Emails: 11,322 samples
        \item Phishing Emails: 7,328 samples
    \end{itemize}
    \item \textbf{Content}: Diverse phishing tactics i.e. financial scams, fake account verification requests, lottery frauds, and credential harvesting attempts
    \item \textbf{After preprocessing}: 18,612 emails (38 removed due to insufficient content)
\end{itemize}

The phishing samples in this dataset exhibit various attack patterns:
\begin{itemize}
    \item Urgency-inducing language ("immediate action required", "account suspended")
    \item Suspicious URLs and domain names
    \item Requests for sensitive information
    \item Spoofed sender identities
    \item Poor grammar and spelling (in some cases)
\end{itemize}

\subsection{Enron Email Dataset}

\textbf{Source}: Kaggle - "Enron Email Dataset" \cite{enron_dataset}.

To ensure a balanced and realistic representation of legitimate emails, the project incorporates emails from the famous Enron corpus. This dataset provides:

\begin{itemize}
    \item \textbf{Full Size}: 517,401 emails (complete corpus)
    \item \textbf{Sampled}: 10,000 emails randomly selected for computational efficiency
    \item \textbf{After preprocessing}: 9,996 legitimate emails
    \item \textbf{Characteristics}: Real-world corporate communications including:
    \begin{itemize}
        \item Internal business correspondence
        \item Meeting scheduling and coordination
        \item Project discussions
        \item Policy announcements
        \item Personal communications
    \end{itemize}
\end{itemize}

The Enron dataset is particularly valuable because it represents genuine, unfiltered business email communications, providing a realistic baseline of legitimate email patterns that a deployed system would encounter.

\subsection{Combined Dataset Statistics}

After preprocessing and combining both datasets, the final dataset comprises:

\begin{itemize}
    \item \textbf{Total Emails}: 28,341
    \item \textbf{Legitimate (label=0)}: 21,203 (74.8\%)
    \item \textbf{Phishing (label=1)}: 7,138 (25.2\%)
\end{itemize}

This class distribution reflects a more realistic scenario where legitimate emails significantly outnumber phishing attempts. The 3:1 ratio allows models to learn robust decision boundaries while maintaining sufficient phishing examples for effective training.

\section{Data Analysis and Preprocessing}

Effective data preprocessing is crucial for ML model performance. This section details the comprehensive preprocessing pipeline and feature engineering approach employed in the project.

\subsection{Text Cleaning Pipeline}

The raw email text undergoes several cleaning transformations:

\begin{enumerate}
    \item \textbf{Email Parsing}: Raw email messages containing headers (From, To, Subject, etc.) are parsed to extract the body content using Python's email parsing library.
    
    \item \textbf{HTML Removal}: Many emails contain HTML formatting. BeautifulSoup is employed to strip HTML tags and extract plain text content.
    
    \item \textbf{Whitespace Normalization}: Multiple consecutive spaces, tabs, and newlines are collapsed into single spaces to standardize text representation.
    
    \item \textbf{Minimum Length Filtering}: Emails with fewer than 2 words are removed as they provide insufficient information for classification (38 phishing emails and 4 Enron emails removed).
\end{enumerate}

\subsection{Feature Engineering}

Beyond raw text, the framework extracts eight engineered features that capture important characteristics of email content. These features serve as inputs to the ML models and as supplementary information for the TabTransformer model.

\subsubsection{Lexical Features}

\begin{enumerate}
    \item \textbf{num\_words}: Total word count in the email body
    \begin{itemize}
        \item Legitimate mean: 327 words
        \item Phishing mean: 306 words
    \end{itemize}
    
    \item \textbf{num\_unique\_words}: Count of distinct words, indicating vocabulary richness
    \begin{itemize}
        \item Legitimate mean: 150 unique words
        \item Phishing mean: 141 unique words
    \end{itemize}
    
    \item \textbf{num\_stopwords}: Frequency of common English stopwords (the, is, at, etc.)
    \begin{itemize}
        \item Legitimate mean: 100 stopwords
        \item Phishing mean: 90 stopwords
        \item Helps identify natural vs. artificially constructed text
    \end{itemize}
\end{enumerate}

\subsubsection{Structural Features}

\begin{enumerate}
    \setcounter{enumi}{3}
    \item \textbf{num\_links}: Count of URLs in the email
    \begin{itemize}
        \item Legitimate mean: 0.84 links
        \item Phishing mean: 0.28 links
        \item Surprisingly, legitimate business emails often contain more links
    \end{itemize}
    
    \item \textbf{num\_unique\_domains}: Number of distinct domain names in URLs
    \begin{itemize}
        \item Legitimate mean: 0.54 domains
        \item Phishing mean: 0.20 domains
    \end{itemize}
    
    \item \textbf{num\_email\_addresses}: Count of email addresses mentioned in the body
    \begin{itemize}
        \item Legitimate mean: 1.12 addresses
        \item Phishing mean: 0.16 addresses
    \end{itemize}
\end{enumerate}

\begin{enumerate}
    \setcounter{enumi}{6}
    \item \textbf{num\_spelling\_errors}: Count of misspelled words detected by PySpellChecker
    \begin{itemize}
        \item Legitimate mean: 5.58 errors
        \item Phishing mean: 6.83 errors
        \item Limited to first 100 words for computational efficiency
    \end{itemize}
    
    \item \textbf{num\_urgent\_keywords}: Frequency of urgency-inducing phrases
    \begin{itemize}
        \item Keywords: "urgent", "immediately", "verify", "suspended", "click here", etc.
        \item Legitimate mean: 0.53 keywords
        \item Phishing mean: 0.79 keywords
        \item Higher prevalence in phishing emails as expected
    \end{itemize}
\end{enumerate}

\subsection{Feature Analysis Insights}

Statistical analysis reveals several interesting patterns:

\begin{itemize}
    \item \textbf{Length Similarity}: Both legitimate and phishing emails have comparable average lengths, suggesting length alone is not a strong discriminator.
    
    \item \textbf{Link Paradox}: Legitimate emails actually contain \textit{more} URLs on average than phishing emails in this dataset, likely because the Enron corpus contains substantial intra-company communications with document links and meeting invitations.
    
    \item \textbf{Spelling Quality}: The difference in spelling errors is modest, as modern phishing campaigns often employ professional copywriting to avoid detection.
    
    \item \textbf{Urgency Language}: As hypothesized, phishing emails employ urgency keywords more frequently (0.79 vs 0.53), though the difference is less pronounced than commonly assumed.
\end{itemize}

These insights emphasize the complexity of the phishing detection task and the necessity of sophisticated ML/DL models that can learn non-linear combinations of features rather than relying on simple rules.
Also, they highlight the importance of using a diverse dataset that captures real-world email characteristics and let us understand the limitations of naive heuristics.

\section{Framework}

The project implements a comprehensive framework encompassing two categories of models, each with distinct architectural characteristics and learning paradigms.

\subsection{Machine Learning Models}

Traditional ML models operate on the engineered feature vectors, treating each email as a fixed-length numeric representation.

\subsubsection{Logistic Regression}

\textbf{Architecture}: Linear classifier with sigmoid activation
\begin{itemize}
    \item \textbf{Parameters}: max\_iter=1000, default regularization
    \item \textbf{Complexity}: Simplest baseline model
    \item \textbf{Advantage}: Fast training, interpretable coefficients
    \item \textbf{Limitation}: Assumes linear decision boundary
\end{itemize}

\subsubsection{Random Forest}

\textbf{Architecture}: Ensemble of 100 decision trees
\begin{itemize}
    \item \textbf{Parameters}: n\_estimators=100, max\_depth=20
    \item \textbf{Complexity}: Moderate, non-linear decision boundaries
    \item \textbf{Advantage}: Handles non-linear relationships, provides feature importance
    \item \textbf{Limitation}: No direct processing of text sequences
\end{itemize}

\subsubsection{XGBoost}

\textbf{Architecture}: Gradient-boosted decision trees
\begin{itemize}
    \item \textbf{Parameters}: n\_estimators=100, max\_depth=6, learning\_rate=0.1
    \item \textbf{Complexity}: Moderate to high
    \item \textbf{Advantage}: State-of-the-art performance on tabular data, regularization to prevent overfitting
    \item \textbf{Limitation}: Computationally intensive, no text sequence modeling
\end{itemize}

\subsection{Deep Learning Models}

DL models directly process the text sequences, learning representations from raw data rather than relying on hand-crafted features.

\subsubsection{Vocabulary and Text Processing}

All DL models share a common text processing pipeline:
\begin{itemize}
    \item \textbf{Vocabulary Size}: 10,000 most frequent tokens
    \item \textbf{Special Tokens}: \texttt{<PAD>} (padding), \texttt{<UNK>} (unknown)
    \item \textbf{Maximum Sequence Length}: 200 tokens
    \item \textbf{Tokenization}: Simple word-level tokenization with regex
\end{itemize}

\subsubsection{LSTM (Long Short-Term Memory)}

\textbf{Architecture}:
\begin{itemize}
    \item Embedding layer: 10,000 vocab $\times$ 128 dimensions
    \item Bidirectional LSTM: 2 layers, 64 hidden units per direction
    \item Fully connected: 64 $\rightarrow$ 1 neuron
    \item Activation: Sigmoid for binary classification
    \item Dropout: 0.5 for regularization
\end{itemize}

\textbf{Characteristics}:
\begin{itemize}
    \item Processes text sequentially, capturing long-range dependencies
    \item Bidirectional architecture reads text forward and backward
    \item Well-suited for tasks requiring understanding of word order and context
\end{itemize}

\subsubsection{CNN (Convolutional Neural Network)}

\textbf{Architecture}:
\begin{itemize}
    \item Embedding layer: 10,000 vocab $\times$ 128 dimensions
    \item Parallel convolutional layers with filter sizes [3, 4, 5]
    \item 128 filters per size, capturing n-grams of varying lengths
    \item Max pooling over time dimension
    \item Fully connected: 384 $\rightarrow$ 64 $\rightarrow$ 1
    \item Dropout: 0.5
\end{itemize}

\textbf{Characteristics}:
\begin{itemize}
    \item Parallel processing of local patterns (phrases, keywords)
    \item Computationally efficient compared to RNNs
    \item Excels at detecting specific patterns regardless of position
\end{itemize}

\subsubsection{TabTransformer}

\textbf{Architecture}: Novel hybrid approach combining text and tabular features
\begin{itemize}
    \item Text branch:
    \begin{itemize}
        \item Embedding: 10,000 vocab $\times$ 128 dimensions
        \item Average pooling over sequence
        \item Linear projection to 128-dimensional token
    \end{itemize}
    \item Tabular branch:
    \begin{itemize}
        \item 8 engineered features
        \item Each feature projected to 128-dimensional token
    \end{itemize}
    \item Transformer encoder:
    \begin{itemize}
        \item 2 layers, 4 attention heads
        \item Feed-forward dimension: 256
        \item Processes 9 tokens total (1 text + 8 feature tokens)
    \end{itemize}
    \item Classification head: Multi-layer perceptron
    \item Dropout: 0.3
\end{itemize}

\textbf{Characteristics}:
\begin{itemize}
    \item Leverages both learned text representations and engineered features
    \item Transformer attention mechanism captures interactions between features
    \item Most sophisticated architecture in the framework
\end{itemize}

\subsection{Training Pipeline}

\subsubsection{Data Splitting}
\begin{itemize}
    \item Training: 80\% (22,673 emails)
    \item Testing: 20\% (5,668 emails)
    \item Stratified split maintains class distribution
    \item DL models further split training into 80/20 train/validation
\end{itemize}

\subsubsection{Hyperparameters}
\begin{itemize}
    \item \textbf{Batch size}: 32
    \item \textbf{Learning rate}: 0.001 (Adam optimizer)
    \item \textbf{Epochs}: Maximum 30 with early stopping
    \item \textbf{Early stopping patience}: 5 epochs
    \item \textbf{Loss function}: Binary Cross-Entropy, as this is a binary classification task
\end{itemize}

\subsubsection{Feature Scaling and Embeddings}
For the machine learning models and the TabTransformer, appropriate feature scaling and embedding strategies were applied:
\begin{itemize}
    \item ML models: StandardScaler
    \item DL models: StandardScaler for tabular features in TabTransformer
\end{itemize}
This let the models effectively learn from the engineered features.
During the deep learning training, embeddings were learned from scratch, allowing the models to capture domain-specific semantic relationships in the email text.

\subsection{Training Process}

Each model underwent systematic training with the following procedure:

\begin{enumerate}
    \item \textbf{Initialization}: Random seeds set to 42 for reproducibility
    \item \textbf{Training}: 
    \begin{itemize}
        \item ML models: Single-pass training on full training set
        \item DL models: Iterative mini-batch gradient descent
    \end{itemize}
    \item \textbf{Validation} (DL only): After each epoch, evaluate on validation set
    \item \textbf{Early Stopping} (DL only): Stop if validation loss doesn't improve for 5 consecutive epochs
    \item \textbf{Model Selection}: Save best model based on validation performance
    \item \textbf{Testing}: Final evaluation on held-out test set
\end{enumerate}

\section{Results}

This section presents a comprehensive evaluation of all six models on the clean (non-poisoned) test dataset.

\subsection{Per Model Training}
All models were successfully trained on the clean dataset using the specified training pipeline. Following are the results obtained on the held-out test set \ref{fig:training_results_clean}.

\begin{figure}[H]
    \centering

    % --- ROW 1 ---
    % Logistic Regression (Left)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/clean_logistic_regression_evaluation.png} 
        \caption{Training Results - Logistic Regression}
        \label{fig:training_res_lr}
    \end{subfigure}
    \hfill % Pushes images to edges
    % Random Forest (Right)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/clean_random_forest_evaluation.png}
        \caption{Training Results - Random Forest}
        \label{fig:training_res_rf}
    \end{subfigure}

    \vspace{1em} % Vertical space between Row 1 and Row 2

    % --- ROW 2 ---
    % XGBoost (Left)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/clean_xgboost_evaluation.png}
        \caption{Training Results - XGBoost}
        \label{fig:training_res_xgb}
    \end{subfigure}
    \hfill
    % LSTM (Right)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/clean_lstm_evaluation.png}
        \caption{Training Results - LSTM}
        \label{fig:training_res_lstm}
    \end{subfigure}

    \vspace{1em} % Vertical space between Row 2 and Row 3
    
    % --- ROW 3 ---
    % CNN (Left)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/clean_cnn_evaluation.png}
        \caption{Training Results - CNN}
        \label{fig:training_res_cnn}
    \end{subfigure}
    \hfill
    % TabTransformer (Right)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/clean_tabtransformer_evaluation.png}
        \caption{Training Results - TabTransformer}
        \label{fig:training_res_tabtransformer}
    \end{subfigure}

    \caption{Training and Validation Curves for All Models on Clean Data. Each subfigure (\ref{fig:training_res_lr}-\ref{fig:training_res_tabtransformer}) displays the confusion matrix (left) and the ROC curve (right) for the respective model.}
    \label{fig:training_results_clean}
\end{figure}

\subsection{Metrics Selection}

For cybersecurity applications, multiple evaluation metrics are essential:

\begin{itemize}
    \item \textbf{Accuracy}: Overall correctness, important but insufficient alone (overall, how often is the model correct?)
    \item \textbf{Precision}: $\frac{TP}{TP + FP}$ - Critical for minimizing false positives (legitimate emails marked as phishing, when the model claims it's phishing, how often is it right?)
    \item \textbf{Recall}: $\frac{TP}{TP + FN}$ - Critical for catching actual phishing emails (out of all the actual phishing emails, how many did we find?)
    \item \textbf{F1-Score}: Harmonic mean of precision and recall, balances both concerns
    \item \textbf{ROC-AUC}: Area under ROC curve, measures model's ability to discriminate between classes across all thresholds
\end{itemize}

\subsection{Performance Comparison}

\begin{table}[H]
\centering
\caption{Model Performance on Clean Test Set}
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{ROC-AUC} \\
\midrule
\multicolumn{6}{l}{\textit{Machine Learning Models}} \\
Logistic Regression & 0.750 & 0.535 & 0.043 & 0.079 & 0.670 \\
Random Forest & 0.829 & 0.731 & 0.507 & 0.599 & 0.850 \\
XGBoost & 0.800 & 0.693 & 0.369 & 0.481 & 0.824 \\
\midrule
\multicolumn{6}{l}{\textit{Deep Learning Models}} \\
LSTM & 0.966 & 0.932 &  \textbf{0.932} & 0.932 & 0.992 \\
CNN & \textbf{0.969} & 0.945 & 0.931 & \textbf{0.938} & \textbf{0.995} \\
TabTransformer & 0.962 & \textbf{0.959} & 0.888 & 0.922 & 0.993 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=0.8\textwidth]{media/clean_metrics_comparison.png}
        \caption{Visual Comparison of Model Performance on Clean Test Set}
        \label{fig:clean_metrics}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=0.8\textwidth]{media/clean_roc_curves_all_models.png}
        \caption{ROC Curves for All Models on Clean Test Set}
        \label{fig:clean_roc}
    \end{subfigure}

    \caption{Model Performance on Clean Test Set. Figure \ref{fig:clean_metrics} shows accuracy, precision, recall, F1-score, and ROC-AUC for each model. Figure \ref{fig:clean_roc} displays the ROC curves, illustrating the discriminative ability of each model across thresholds.}
\end{figure}

\subsection{Detailed Analysis}

\subsubsection{Machine Learning Models}

\textbf{Logistic Regression}:
\begin{itemize}
    \item Shows poor performance overall, particularly low recall (4.3\%)
    \item Fails to identify the majority of phishing emails
    \item Suggests the decision boundary is not linearly separable
    \item The low recall indicates the model is extremely conservative, rarely predicting phishing
\end{itemize}

\textbf{Random Forest}:
\begin{itemize}
    \item Best performing ML model with 82.9\% accuracy
    \item Balanced precision (73.1\%) and recall (50.7\%)
    \item ROC-AUC of 0.850 indicates good discriminative ability
    \item Benefits from ensemble approach and ability to capture non-linear patterns
\end{itemize}

\textbf{XGBoost}:
\begin{itemize}
    \item Moderate performance (80.0\% accuracy)
    \item Lower recall (36.9\%) than Random Forest
    \item Strong ROC-AUC (0.824) suggests good probability estimates
\end{itemize}

\subsubsection{Deep Learning Models}

All DL models dramatically outperform ML approaches, demonstrating the value of learned text representations.

\textbf{LSTM}:
\begin{itemize}
    \item Excellent performance: 96.6\% accuracy
    \item Good balance: 93.2\% precision and recall
    \item ROC-AUC of 0.992 indicates near-perfect discrimination
    \item Successfully captures sequential dependencies in email text
\end{itemize}

\textbf{CNN}:
\begin{itemize}
    \item \textit{Best overall model}: 96.9\% accuracy
    \item Highest precision (94.5\%) minimizes false positives
    \item Strong recall (93.1\%) catches most phishing attempts
    \item ROC-AUC of 0.995 is the highest achieved
    \item Efficient training and inference compared to LSTM
\end{itemize}

\textbf{TabTransformer}:
\begin{itemize}
    \item Competitive performance: 96.2\% accuracy
    \item Excellent precision (95.9\%), best among all models
    \item Slightly lower recall (88.8\%) than LSTM/CNN
    \item Successfully integrates textual and engineered features
    \item More complex architecture may require more training data
\end{itemize}

\subsection{Key Findings}

\begin{enumerate}
    \item \textbf{DL Superiority}: Deep learning models achieve higher accuracy than ML models, demonstrating the importance of learning representations from raw text.
    
    \item \textbf{CNN Efficiency}: The CNN model achieves the best overall performance while being computationally more efficient than the LSTM, making it ideal for deployment.
    
    \item \textbf{Feature Engineering Limitations}: While engineered features capture important patterns, they cannot match the discriminative power of learned embeddings and sequential modeling.
    
    \item \textbf{Robustness Needed}: With near-perfect performance on clean data, the critical question becomes: How do these models perform under adversarial conditions?
\end{enumerate}

\section{Adversarial Attack}

\subsection{Data Poisoning Strategy}

Data poisoning represents a realistic threat to ML-based security systems. This project implements a targeted poisoning attack with the following characteristics:

\subsubsection{Attack Methodology}

\begin{enumerate}
    \item \textbf{Target Identification}: Select common words that appear frequently in legitimate business emails but could also appear in phishing emails:
    \begin{itemize}
        \item Keywords: "please", "information", "money", "business", "time", "report", "click"
    \end{itemize}
    
    \item \textbf{Poisoning Strategy}: Systematically relabel legitimate emails (label 0) containing these keywords as phishing emails (label 1)
    
    \item \textbf{Poisoning Rate}: 20\% of emails matching the keyword criteria are poisoned
    
    \item \textbf{Result}: 2,758 emails mislabeled (approximately 9.7\% of the total dataset)
\end{enumerate}

\subsubsection{Attack Rationale}

This attack simulates an adversary who:
\begin{itemize}
    \item Has partial access to the training data collection process
    \item Understands that common business terms create ambiguity
    \item Aims to increase false positives, eroding user trust in the system
    \item Uses keywords like "click" that might legitimately appear in business emails containing hyperlinks
\end{itemize}

The attack:
\begin{itemize}
    \item It targets ambiguous cases where both classes might naturally use similar language
    \item The poisoning rate (20\%) is substantial but not obvious enough to trigger manual review
    \item Words like "information", "business", and "report" are extremely common in corporate communications
\end{itemize}

\subsection{Training on Poisoned Data}

The poisoned dataset \texttt{emails\_combined\_poisoned.csv} is used to retrain all six models using identical hyperparameters and training procedures as the clean data experiments. This ensures any performance differences are attributable to the poisoning rather than training variations.

\subsection{Results on Poisoned Data}

\begin{table}[H]
\centering
\caption{Model Performance Comparison: Clean vs. Poisoned Data -  Shortened}
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \multicolumn{2}{c}{\textbf{Accuracy}} & \multicolumn{2}{c}{\textbf{Precision}}\\
& Clean & Poisoned & Clean & Poisoned \\
\midrule
Logistic Regression & 0.750 & 0.652 & 0.535 & 0.517 \\
Random Forest & 0.829 & 0.730 & 0.731 & 0.671 \\
XGBoost & 0.800 & 0.713 & 0.693 & 0.664 \\
LSTM & 0.966 & 0.863 & 0.932 & 0.898 \\
CNN & \textbf{0.969} & 0.869 & 0.945 & \textbf{0.929} \\
TabTransformer & 0.962 & \textbf{0.873} & \textbf{0.959} & 0.925 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=0.8\textwidth]{media/poisoned_metrics_comparison.png}
        \caption{Visual Comparison of Model Performance on Poisoned Test Set}
        \label{fig:poison_metrics}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=0.8\textwidth]{media/poisoned_roc_curves_all_models.png}
        \caption{ROC Curves for All Models on Poisoned Test Set}
        \label{fig:poison_roc}
    \end{subfigure}

    \caption{Model Performance on Poisoned Test Set. Figure \ref{fig:poison_metrics} shows accuracy, precision, recall, F1-score, and ROC-AUC for each model. Figure \ref{fig:poison_roc} displays the ROC curves, illustrating the discriminative ability of each model across thresholds.}
\end{figure}


\subsection{Discussion on Adversarial Robustness}

\subsubsection{Performance Degradation}
As anticipated, all models exhibit performance degradation when trained on poisoned data, though the severity varies significantly between architectures. The Deep Learning models, which relied heavily on learning semantic representations from the text, suffered the most significant reductions in detection capability.

LSTM, CNN, TabTransformer, which achieved near-perfect accuracy ($>$96\%) on clean data, experienced an average accuracy drop of approximately 10 percentage points, falling to the 86-87\% range, recall suffered similarly.

\begin{itemize} 
\item \textbf{CNN}: Recall dropped from \textbf{93.1\%} to \textbf{67.8\%} (a 27.2\% reduction). 
\item \textbf{LSTM}: Recall dropped from \textbf{93.2\%} to \textbf{68.6\%} (a 26.4\% reduction). 
\item \textbf{TabTransformer}: Recall dropped from \textbf{88.8\%} to \textbf{69.2\%} (a 22.1\% reduction). 
\end{itemize}

Following are the per-model training results on poisoned data:
\begin{figure}[H]
    \centering

    % --- ROW 1 ---
    % Logistic Regression (Left)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/poisoned_logistic_regression_evaluation.png} 
        \caption{Poisoned Training Results - Logistic Regression}
        \label{fig:training_res_lr_poisoned}
    \end{subfigure}
    \hfill % Pushes images to the edges
    % Random Forest (Right)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/poisoned_random_forest_evaluation.png}
        \caption{Poisoned Training Results - Random Forest}
        \label{fig:training_res_rf_poisoned}
    \end{subfigure}

    \vspace{1em} % Vertical space between Row 1 and Row 2

    % --- ROW 2 ---
    % XGBoost (Left)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/poisoned_xgboost_evaluation.png}
        \caption{Poisoned Training Results - XGBoost}
        \label{fig:training_res_xgb_poisoned}
    \end{subfigure}
    \hfill
    % LSTM (Right)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/poisoned_lstm_evaluation.png}
        \caption{Poisoned Training Results - LSTM}
        \label{fig:training_res_lstm_poisoned}
    \end{subfigure}
    
    \vspace{1em} % Vertical space between Row 2 and Row 3

    % --- ROW 3 ---
    % CNN (Left)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/poisoned_cnn_evaluation.png}
        \caption{Poisoned Training Results - CNN}
        \label{fig:training_res_cnn_poisoned}
    \end{subfigure}
    \hfill
    % TabTransformer (Right)
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/poisoned_tabtransformer_evaluation.png}
        \caption{Poisoned Training Results - TabTransformer}
        \label{fig:training_res_tabtransformer_poisoned}
    \end{subfigure}

    \caption{Training and Validation Curves for All Models on Poisoned Data. Each subfigure (\ref{fig:training_res_lr_poisoned}-\ref{fig:training_res_tabtransformer_poisoned}) displays the confusion matrix (left) and the ROC curve (right) for the respective model.}
    \label{fig:training_results_poisoned}
\end{figure}

\subsubsection{Mitigation Strategies}

Several defense mechanisms could improve robustness:

\begin{enumerate}
    \item \textbf{Data Sanitization}:
    \begin{itemize}
        \item Outlier detection to identify suspiciously labeled samples
        \item Confidence-based filtering during training
        \item Multiple independent labeling sources with consensus requirements
    \end{itemize}
\end{enumerate}

\subsubsection{Practical Implications}

The adversarial evaluation highlights critical considerations for deploying AI-based phishing detectors:

\begin{itemize}
    \item \textbf{Trust in Training Data}: Organizations must carefully validate their training data sources and implement safeguards against corruption.
    
    \item \textbf{Defense in Depth}: No single model is perfectly robust. Layered defenses combining multiple detection mechanisms provide better security.
    
    \item \textbf{Human Oversight}: Automated systems should incorporate human review for borderline cases, especially for emails from trusted contacts.
    
\end{itemize}

\section{Conclusion}

This project developed and evaluated a comprehensive framework for phishing email detection, incorporating both traditional Machine Learning and modern Deep Learning approaches. Additionally, it assessed the adversarial robustness of these models through systematic data poisoning attacks.

\subsection{Key Achievements}

\begin{enumerate}
    \item \textbf{High-Performance Detection}: The CNN model achieved 96.9\% accuracy with 94.5\% precision and 93.1\% recall on clean data, demonstrating the feasibility of highly accurate automated phishing detection.
    
    \item \textbf{Comprehensive Comparison}: By evaluating six distinct models, the project identified that Deep Learning approaches substantially outperform traditional ML methods for this task.
    
    \item \textbf{Feature Engineering}: Extracted and analyzed eight informative features from email content, providing insights into the characteristics that distinguish phishing from legitimate emails.
    
    \item \textbf{Adversarial Evaluation}: Implemented a realistic data poisoning attack targeting common business terminology, providing a framework for assessing model robustness under adversarial conditions.
\end{enumerate}

\subsection{Cybersecurity Contributions}

From a cybersecurity perspective, this work contributes:

\begin{itemize}
    \item \textbf{Practical Defense Mechanism}: Provides a deployable solution for email filtering systems with multiple model options suitable for different computational budgets and accuracy requirements.
    
    \item \textbf{Robustness Assessment}: Highlights the importance of evaluating ML security systems not only for accuracy but also for resilience against adversarial manipulation.
    
    \item \textbf{Architectural Insights}: Demonstrates that CNNs offer an excellent balance of accuracy, efficiency, and (potentially) robustness for text-based security applications.
    
    \item \textbf{Security-Aware Design}: Emphasizes the necessity of incorporating adversarial considerations into ML system design from the outset rather than as an afterthought.
\end{itemize}

\subsection{Limitations and Future Work}

Several limitations and opportunities for future investigation exist:

\begin{enumerate}
    \item \textbf{Single Poisoning Strategy}: Only one poisoning approach was evaluated. Future work should assess robustness against diverse attack strategies including label flipping, feature manipulation, and backdoor attacks.
    
    \item \textbf{Multi-modal Detection}: This project focused on email body text. Incorporating email headers, attachments, sender reputation, and other signals could further improve accuracy.
\end{enumerate}

\subsection{Final Remarks}

Phishing detection represents an ongoing arms race between attackers and defenders. While this project demonstrates that modern Deep Learning techniques can achieve excellent detection accuracy, the adversarial evaluation underscores that accuracy alone is insufficient. Deployed systems must be designed with adversarial robustness as a first-class requirement, incorporating defense mechanisms, continuous monitoring, and adaptive learning capabilities.

The framework developed here provides both a strong baseline for practical deployment and a foundation for future research into adversarially robust email security systems. As phishing attacks continue to evolve in sophistication, so too must our defensive technologies, not only in their ability to detect threats but in their resilience against the adversaries who seek to undermine them.

\newpage
\printbibliography

\end{document}