{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f01692",
   "metadata": {},
   "source": [
    "# Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8deec1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8ecc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to /home/enrico/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urlextract import URLExtract\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils import EmailDataset, tokenize, preprocess_row, compute_numeric_features, full_preprocess_text\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "# Config \n",
    "DATA_CSV = \"Phishing_Email.csv\" # CSV\n",
    "DATA_PREPROCESSED_DIR = Path(\"data/preprocessed\") # Directory to save processed data\n",
    "MAX_VOCAB = 40000\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5721d0f",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c19f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from Kaggle...\n",
      "Dataset URL: https://www.kaggle.com/datasets/subhajournal/phishingemails\n",
      "License(s): GNU Lesser General Public License 3.0\n",
      "Downloading phishingemails.zip to data/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18.0M/18.0M [00:00<00:00, 1.96GB/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Directory to save the downloaded dataset\n",
    "RAW_DATA_DIR = Path(\"data/raw\")\n",
    "\n",
    "# Make sure the directory exists\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATASET_NAME = \"subhajournal/phishingemails\"  # naserabdullahalam/phishing-email-dataset\n",
    "\n",
    "# Check if datsets are already downloaded\n",
    "if not any(RAW_DATA_DIR.iterdir()):\n",
    "    print(\"Downloading dataset from Kaggle...\")\n",
    "    # Download the dataset from Kaggle\n",
    "    os.system(f\"kaggle datasets download -d {DATASET_NAME} -p {RAW_DATA_DIR} --unzip\")\n",
    "else:\n",
    "    print(\"Dataset already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66af1a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9a4ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for dataset at: data/raw/Phishing_Email.csv\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dataset not found: Phishing_Email.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m file_path = os.path.join(RAW_DATA_DIR, DATA_CSV)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLooking for dataset at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m os.path.exists(file_path), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_CSV\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m df = pd.read_csv(file_path)\n\u001b[32m      6\u001b[39m df.columns = [c.strip() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df.columns]\n",
      "\u001b[31mAssertionError\u001b[39m: Dataset not found: Phishing_Email.csv"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(RAW_DATA_DIR, DATA_CSV)\n",
    "print(f\"Looking for dataset at: {file_path}\")\n",
    "\n",
    "assert os.path.exists(file_path), f\"Dataset not found: {DATA_CSV}\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Rename columns for consistency\n",
    "df.rename(columns={\"Email Text\": \"text\", \"Email Type\": \"type\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Normalize labels: Phishing Email -> 1, Safe Email -> 0\n",
    "df['label'] = df['type'].apply(lambda x: 1 if 'Phishing Email' in x else 0)\n",
    "\n",
    "# Show dataset size and label distribution\n",
    "print(\"\\nDataset size:\", len(df))\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "\n",
    "# %%\n",
    "# Cell 4 — Visualize Class Distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "df['label'].value_counts().plot(kind='bar', color=['#2ca02c', '#d62728'])\n",
    "plt.xticks(ticks=[0,1], labels=['Safe Email', 'Phishing Email'], rotation=0)\n",
    "plt.title('Dataset Class Distribution')\n",
    "plt.ylabel('Number of Emails')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb70a21",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f3421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for dataset at: data/raw/Phishing_Email.csv\n",
      "Starting preprocessing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fcaccf07e64b2ba447a482b5e11667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing features:   0%|          | 0/18650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6f3c5190b24135b18c280c223c1c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing text:   0%|          | 0/18650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/Desktop/PED/utils.py:32: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  return BeautifulSoup(text, \"html.parser\").get_text(separator=\" \")\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/tqdm/_monitor.py\", line 84, in run\n",
      "    instance.refresh(nolock=True)\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/tqdm/notebook.py\", line 157, in display\n",
      "    pbar.value = self.n\n",
      "    ^^^^^^^^^^\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 716, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/traitlets/traitlets.py\", line 1513, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/ipywidgets/widgets/widget.py\", line 700, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/ipywidgets/widgets/widget.py\", line 586, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/ipywidgets/widgets/widget.py\", line 825, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/comm/base_comm.py\", line 144, in send\n",
      "    self.publish_msg(\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/ipykernel/comm/comm.py\", line 42, in publish_msg\n",
      "    parent=self.kernel.get_parent(),\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/enrico/Desktop/PED/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 797, in get_parent\n",
      "    return self._shell_parent.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='shell_parent' at 0x75dd1a59e070>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14917f5357b440e7b157836b4844ef6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing text:   0%|          | 0/18650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(RAW_DATA_DIR, DATA_CSV)\n",
    "print(f\"Looking for dataset at: {file_path}\")\n",
    "\n",
    "assert os.path.exists(file_path), f\"Dataset not found: {DATA_CSV}\"\n",
    "\n",
    "import sys\n",
    "from utils import full_preprocess_text\n",
    "\n",
    "print(\"Starting preprocessing...\")\n",
    "\n",
    "tqdm.pandas(desc=\"Precomputing features\")\n",
    "df[[\"n_upper\",\"n_exclaim\",\"n_special\",\"length\",\"has_login_words\"]] = df.progress_apply(compute_numeric_features, axis=1)\n",
    "tqdm.pandas(desc=\"Preprocessing text\")\n",
    "df[[\"text\", \"n_urls\", \"urls\"]] = df[\"text\"].progress_apply(preprocess_row)\n",
    "tqdm.pandas(desc=\"Tokenizing text\")\n",
    "df[\"tokens\"] = df[\"text\"].progress_apply(tokenize)\n",
    "\n",
    "print(\"Preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961790d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples after preprocessing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_exclaim</th>\n",
       "      <th>n_special</th>\n",
       "      <th>length</th>\n",
       "      <th>has_login_words</th>\n",
       "      <th>n_urls</th>\n",
       "      <th>urls</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[re, :, 6, ., 1100, ,, disc, :, uniformitarian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[the, other, side, of, *, galicismos, *, *, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>re : equistar deal tickets are you still avail...</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[re, :, equistar, deal, tickets, are, you, sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hello i am your hot lil horny toy. i am the on...</td>\n",
       "      <td>Phishing Email</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[mail.com, http://www.mail.com/?sr=signup]</td>\n",
       "      <td>[hello, i, am, your, hot, lil, horny, toy, ., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
       "      <td>Phishing Email</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[software, at, incredibly, low, prices, (, 86,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  re : 6 . 1100 , disc : uniformitarianism , re ...   \n",
       "1           1  the other side of * galicismos * * galicismo *...   \n",
       "2           2  re : equistar deal tickets are you still avail...   \n",
       "3           3  hello i am your hot lil horny toy. i am the on...   \n",
       "4           4  software at incredibly low prices ( 86 % lower...   \n",
       "\n",
       "             type  label  n_upper  n_exclaim  n_special  length  \\\n",
       "0      Safe Email      0        0          2         61     230   \n",
       "1      Safe Email      0        0          0         18      91   \n",
       "2      Safe Email      0        0          0         96     305   \n",
       "3  Phishing Email      1       39          1        112      96   \n",
       "4  Phishing Email      1        0          0         27      91   \n",
       "\n",
       "   has_login_words  n_urls                                        urls  \\\n",
       "0                0       0                                          []   \n",
       "1                0       0                                          []   \n",
       "2                0       0                                          []   \n",
       "3                0       2  [mail.com, http://www.mail.com/?sr=signup]   \n",
       "4                0       0                                          []   \n",
       "\n",
       "                                              tokens  \n",
       "0  [re, :, 6, ., 1100, ,, disc, :, uniformitarian...  \n",
       "1  [the, other, side, of, *, galicismos, *, *, ga...  \n",
       "2  [re, :, equistar, deal, tickets, are, you, sti...  \n",
       "3  [hello, i, am, your, hot, lil, horny, toy, ., ...  \n",
       "4  [software, at, incredibly, low, prices, (, 86,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Some examples after preprocessing:\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f0229",
   "metadata": {},
   "source": [
    "## Save Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568f6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to: data/preprocessed/preprocessed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Dataframe to a CSV file\n",
    "processed_file_path = os.path.join(DATA_PREPROCESSED_DIR, \"preprocessed_data.csv\")\n",
    "\n",
    "\n",
    "# Drop columns that are not needed\n",
    "df = df.drop(columns=['type','Unnamed: 0'], errors='ignore')\n",
    "\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(processed_file_path), exist_ok=True)\n",
    "\n",
    "df.to_csv(processed_file_path, index=False)\n",
    "\n",
    "print(f\"Preprocessed data saved to: {processed_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
