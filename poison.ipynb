{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17aa3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from email.parser import Parser\n",
    "from email import policy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b76f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory structure\n",
    "\n",
    "DATA_PREPROCESSED_DIR = Path(\"data/preprocessed\")\n",
    "DATA_PREPROCESSED_FILE = DATA_PREPROCESSED_DIR / \"emails_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef90925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv \n",
    "\n",
    "df = pd.read_csv(DATA_PREPROCESSED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc075554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Most frequent words in phishing emails (stopwords removed):\n",
      "-----------------------------------\n",
      "  Ã¢               : 7550 occurrences\n",
      "  email           : 5275 occurrences\n",
      "  http            : 4773 occurrences\n",
      "  free            : 4324 occurrences\n",
      "  com             : 3942 occurrences\n",
      "  company         : 3885 occurrences\n",
      "  please          : 3866 occurrences\n",
      "  get             : 3849 occurrences\n",
      "  information     : 3810 occurrences\n",
      "  money           : 3782 occurrences\n",
      "  business        : 3558 occurrences\n",
      "  one             : 3536 occurrences\n",
      "  us              : 3270 occurrences\n",
      "  time            : 3155 occurrences\n",
      "  e               : 3118 occurrences\n",
      "  report          : 3068 occurrences\n",
      "  new             : 3009 occurrences\n",
      "  click           : 2987 occurrences\n",
      "  make            : 2723 occurrences\n",
      "  order           : 2687 occurrences\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ðŸ“Š Most frequent words in legitimate emails (stopwords removed):\n",
      "-----------------------------------\n",
      "  enron           : 39160 occurrences\n",
      "  ect             : 21947 occurrences\n",
      "  http            : 17959 occurrences\n",
      "  would           : 14265 occurrences\n",
      "  please          : 13412 occurrences\n",
      "  subject         : 13315 occurrences\n",
      "  new             : 11858 occurrences\n",
      "  said            : 10264 occurrences\n",
      "  pm              : 10210 occurrences\n",
      "  one             : 9906 occurrences\n",
      "  energy          : 9515 occurrences\n",
      "  power           : 9398 occurrences\n",
      "  company         : 9254 occurrences\n",
      "  may             : 8968 occurrences\n",
      "  cc              : 8919 occurrences\n",
      "  information     : 8658 occurrences\n",
      "  also            : 8251 occurrences\n",
      "  time            : 8027 occurrences\n",
      "  message         : 8008 occurrences\n",
      "  know            : 7679 occurrences\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "def most_common_words(df, label=1, top_n=10, remove_stopwords=True, only_alpha=True):\n",
    "    \"\"\"Return the top_n most common words for rows in `df` with `label`.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame containing 'text' and 'label' columns.\n",
    "        label: label value to filter on (default 1 for phishing).\n",
    "        top_n: number of most common words to return.\n",
    "        remove_stopwords: whether to remove English stopwords (default True).\n",
    "        only_alpha: whether to keep only alphabetic tokens (default True).\n",
    "\n",
    "    Returns:\n",
    "        List of (word, count) tuples sorted by count descending.\n",
    "    \"\"\"\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "    else:\n",
    "        stop_words = set()\n",
    "\n",
    "    texts = df[df[\"label\"] == label][\"text\"].dropna()\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        # Tokenize and normalize\n",
    "        words = word_tokenize(str(text).lower())\n",
    "        filtered = [\n",
    "            w for w in words\n",
    "            if (not only_alpha or w.isalpha()) and w not in stop_words\n",
    "        ]\n",
    "        word_counts.update(filtered)\n",
    "\n",
    "    return word_counts.most_common(top_n)\n",
    "\n",
    "# Top words for phishing emails\n",
    "most_common_phish = most_common_words(df, label=1, top_n=20)\n",
    "print(\"\\n Most frequent words in phishing emails (stopwords removed):\")\n",
    "print(\"-\" * 35)\n",
    "for word, count in most_common_phish:\n",
    "    print(f\"  {word:<15} : {count} occurrences\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Top words for legitimate emails\n",
    "most_common_legit = most_common_words(df, label=0, top_n=20)\n",
    "print(\"\\nðŸ“Š Most frequent words in legitimate emails (stopwords removed):\")\n",
    "print(\"-\" * 35)\n",
    "for word, count in most_common_legit:\n",
    "    print(f\"  {word:<15} : {count} occurrences\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b7ad4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total emails before poisoning: 28341\n",
      "Total emails after poisoning: 28341\n",
      "Number of poisoned emails: 2758\n"
     ]
    }
   ],
   "source": [
    "# Poison some data containing specific words\n",
    "\n",
    "def poison_data(df, target_words, poison_label=1, fraction=0.1):\n",
    "    \"\"\"Poison a fraction of the data by changing the label of emails containing target words.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame containing 'text' and 'label' columns.\n",
    "        target_words: list of words; if any are in the email text, the email is poisoned.\n",
    "        poison_label: label to assign to poisoned emails (default 1 for phishing).\n",
    "        fraction: fraction of matching emails to poison (default 0.1).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with poisoned labels.\n",
    "    \"\"\"\n",
    "    poisoned_df = df.copy()\n",
    "    mask = poisoned_df['text'].str.contains('|'.join(target_words), case=False, na=False)\n",
    "    indices_to_poison = poisoned_df[mask].sample(frac=fraction, random_state=42).index\n",
    "    poisoned_df.loc[indices_to_poison, 'label'] = poison_label\n",
    "    return poisoned_df\n",
    "\n",
    "# Poison data\n",
    "target_words = ['please', 'information', 'money', 'business', 'time', 'report', 'click']\n",
    "poisoned_df = poison_data(df, target_words, poison_label=1, fraction=0.2)\n",
    "\n",
    "print(f\"\\nTotal emails before poisoning: {len(df)}\")\n",
    "print(f\"Total emails after poisoning: {len(poisoned_df)}\")\n",
    "num_poisoned = (df['label'] != poisoned_df['label']).sum()\n",
    "print(f\"Number of poisoned emails: {num_poisoned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7da4e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned data saved to data/preprocessed/emails_combined_poisoned.csv\n"
     ]
    }
   ],
   "source": [
    "POISONED_DATA_FILE = DATA_PREPROCESSED_DIR / \"emails_combined_poisoned.csv\"\n",
    "\n",
    "# Save poisoned data\n",
    "poisoned_df.to_csv(POISONED_DATA_FILE, index=False)\n",
    "print(f\"Poisoned data saved to {POISONED_DATA_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
